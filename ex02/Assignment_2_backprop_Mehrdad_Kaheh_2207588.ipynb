{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe3XPSpN6WkP"
      },
      "source": [
        "# 521153S:3, Deep Learning assignment 2: Loss Function, Optimization, Neural Networks, Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-z9xM-66WkT"
      },
      "source": [
        "## Outline \n",
        "#### In this assignment, you will learn:\n",
        "* **Neural Network, Deep Neural Network, Loss Function and Optimization**.\n",
        "* Building a one layer NN using numpy to understand the backpropagation.\n",
        "* Gradient check using finite-difference approximation.\n",
        "* Stochatic Gradient Descent (SGD).\n",
        "* Simple hype-parameters tuning methods to improve your NN performance.\n",
        "\n",
        "#### Grading (<span style=\"color:green\">15 points</span>)\n",
        "In this assignment, we are going to learn about **Neural Network, Deep Neural Network, Loss Function and Optimization**. They are very important knowledge you need to know in deep learning.\n",
        "\n",
        "Hints: First of all , make sure you implement the sigmoid, softmax and cross-entropy loss **correctly**. <br>\n",
        "Then, **implement first the weight decay off (is_weight_decay = False) then move on with (is_weight_decay = True)**\n",
        "* **Part 1.** Import libraries, loading and preprocessing the training and testing data.\n",
        "* **Part 2.** Optimize the neural network according to the loss function. (<span style=\"color:green\">12 points</span>)\n",
        "  * 2.1. Construct model in **Fig. 2** (<span style=\"color:green\">4 points</span>) <br>\n",
        "       * 2.1.1 Declare W1 and W2 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.1.2 Implement sigmoid (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.1.3 Implement softmax (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.1.4 Implement the cross-entropy loss (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "  * 2.2. Implement the forward-pass (<span style=\"color:green\">2.0 point</span>) <br>\n",
        "       * 2.2.1 Foward-pass in training (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.2.2 Call cross entropy loss in training (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "       * 2.2.3 Forward-pass in testing (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "  * 2.3. Implement SGD (<span style=\"color:green\">2 point</span>) <br>\n",
        "       * 2.3.1 Velocity (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.3.2 Update weights (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "  * 2.4. Derivatives <br>\n",
        "       * Derive equations <br> \n",
        "  * 2.5. Implement the derivatives (<span style=\"color:green\">4.0 points</span>) <br>\n",
        "       * 2.5.1 Implement equation 8 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.5.2 Implement equation 6 (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "       * 2.5.3 Implement equation 10 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.5.4 Implement equation 10+11 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.5.5 Implement equation 7 (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "* **Part 3.** Gradient check using finite-difference approximation. (<span style=\"color:green\">0.5 points</span>) (YOU **DON'T NEED** TO WRITE THE CODE FOR THIS) <br>\n",
        "  * Question: why don't we use FDA to calculate the gradient to update our model? (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "* **Part 4.** Regularization and NN simple tunning. (<span style=\"color:green\">2.5 points</span>) <br>\n",
        "  * 4.1. Applying weight decay. (<span style=\"color:green\">1.5 point</span>) <br>\n",
        "       * There are 3 spots you need to fill, (<span style=\"color:green\">0.5 point</span>) each spot.\n",
        "  * 4.2. Change the number of neurons in the hidden layer and report the performance (<span style=\"color:green\">1 point</span>) <br>\n",
        "\n",
        "#### Environment\n",
        "Python 3, Numpy, matplotlib, sklearn\n",
        "\n",
        "#### Dataset\n",
        "* [**Fashion-MNIST**](https://github.com/zalandoresearch/fashion-mnist)\n",
        "is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. Using the Fashion-MNIST give you more room to wiggle your experiments.\n",
        "\n",
        "#### Hints\n",
        "* To find the place where you have to insert your solution, hit Crtl + F and search for **TODO:** . You are NOT suppose to modify the codes from other parts.\n",
        "* **Be careful with the shape** of the weights, gradient, .. of your tensor in your implementation. Double check and make sure the shapes are fit for computation, especially matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to5QRNq86WkX"
      },
      "source": [
        "## Part 1. Import libraries, loading and preprocessing the training and testing data\n",
        "**You don't need to change the code from this part.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F2RkU-OR6WkY"
      },
      "outputs": [],
      "source": [
        "# You will mainly use numpy to construct your NN\n",
        "import numpy as np\n",
        "import matplotlib, time, copy, os, requests, zipfile, sys, shutil\n",
        "# Matplotlib to plot the image\n",
        "import matplotlib.pyplot as plt\n",
        "# Off-the-shelf evaluation functions provided by sklearn\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "# Matplotlib predefined 'magic function'. It will include your graphs in your notebook, next to the code\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMYe_gsz6Wka"
      },
      "source": [
        "### Functions use to download the dataset from google drive\n",
        "The code snipet was taken from [this thread](https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IUHX4y7z6Wka"
      },
      "outputs": [],
      "source": [
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPNXsztz6Wkb"
      },
      "source": [
        "### Functions use to pre-process your training/testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OCFUSa--6Wkb"
      },
      "outputs": [],
      "source": [
        "def reshape_train_data(X):\n",
        "    ''' Input training data has shape (60000, 28, 28)\n",
        "        Input testing data has shape (10000, 28, 28)\n",
        "        where: \n",
        "        60000 is the numbers of input training samples\n",
        "        10000 is the numbers of input testing samples\n",
        "        similar to MNIST, resolution of each sample is 28 x 28\n",
        "    '''\n",
        "    samples, H, W = X.shape\n",
        "    # Reshape input volume to (sample, 784), this mean, your NN input layer will have 784 placeholders\n",
        "    # we scale the RGB values by divide them by 255, this will help improve the training performance\n",
        "    return X.reshape(samples, H * W).T / 255\n",
        "\n",
        "def one_hot_vector(x, num_classes):\n",
        "    # By now, I think you already heard about this so many times\n",
        "    return np.eye(num_classes)[x].T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlCBP7Q46Wkc"
      },
      "source": [
        "### We took care of download the data for you.\n",
        "The fashion-MNIST data will be download and store in your **work_dir/data/fashion_mnist_npy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyJRsMtG6Wkc",
        "outputId": "9d568ab3-ed99-47f9-ff60-f2afc45cf74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data was already downloaded and extracted!\n"
          ]
        }
      ],
      "source": [
        "PATH = './data'\n",
        "if not os.path.exists(PATH):\n",
        "    os.makedirs(PATH)\n",
        "    \n",
        "    file_id = '1DQ2Nf2rY467kyZKOf_CG3Kib5FLv0xQu'\n",
        "    destination = os.path.join(PATH, 'fashion_mnist_npy.zip')\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "    \n",
        "    with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
        "        zip_ref.extractall(PATH)\n",
        "        \n",
        "    print(\"Data downloaded and extracted!\")\n",
        "    \n",
        "    os.remove(destination)\n",
        "    \n",
        "else:\n",
        "    print(\"Data was already downloaded and extracted!\")\n",
        "\n",
        "PATH = os.path.join(PATH, 'fashion_mnist_npy')\n",
        "\n",
        "# The actual meaning of the label of your classes.\n",
        "# E.g. if a output one-hot vector is [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], it used to prepresent a Dress\n",
        "label_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAZQVbW_6Wke"
      },
      "source": [
        "### Finally, we load and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "-l5iqUlT6Wke",
        "outputId": "e7e6d13a-d7f2-4c61-ed59-138a83d30d3c",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the training input\n",
        "X_train = np.load(os.path.join(PATH, 'train_data.npy'))\n",
        "# Load the training labels\n",
        "X_test = np.load(os.path.join(PATH, 'test_data.npy'))\n",
        "# Load the testing input\n",
        "Y_train = np.load(os.path.join(PATH, 'train_labels.npy'))\n",
        "# Load the testing labels\n",
        "Y_test = np.load(os.path.join(PATH, 'test_labels.npy'))\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = len(label_names)\n",
        "# Get the number of training samples and their resolution for reshape\n",
        "num_trains, HEIGHT, WIDTH = X_train.shape\n",
        "\n",
        "# Reshape the training and testing inputs\n",
        "X_train, X_test = reshape_train_data(X_train), reshape_train_data(X_test)\n",
        "\n",
        "# Create one-hot vector for the training and testing labels\n",
        "Y_train, Y_test = one_hot_vector(Y_train, num_classes), one_hot_vector(Y_test, num_classes)\n",
        "\n",
        "\n",
        "# This part use to randomly load some of the training and testing image and the one-hot vectors for checking\n",
        "fig_train, ax_train = plt.subplots(figsize=(16, 8), nrows=1, ncols=5)\n",
        "fig_train.suptitle(\"Random image from the TRAINING set\", y=0.73, fontsize=16, fontweight='bold')\n",
        "\n",
        "fig_test, ax_test = plt.subplots(figsize=(16, 8), nrows=1, ncols=5)\n",
        "fig_test.suptitle(\"Random image from the TESTING set\", y=0.73, fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx in range(5):\n",
        "    i, j = np.random.randint(num_trains), np.random.randint(X_test.shape[0])\n",
        "    \n",
        "    ax_train[idx].imshow(X_train[:,i].reshape(HEIGHT, WIDTH), cmap = matplotlib.cm.binary)\n",
        "    ax_train[idx].set_title(label_names[np.argmax(Y_train[:,i])] + \"\\n\" + str(Y_train[:,i]))\n",
        "    ax_train[idx].axis('off')\n",
        "    \n",
        "    ax_test[idx].imshow(X_test[:,j].reshape(HEIGHT, WIDTH), cmap = matplotlib.cm.binary)\n",
        "    ax_test[idx].set_title(label_names[np.argmax(Y_test[:,j])] + \"\\n\" + str(Y_test[:,j]))\n",
        "    ax_test[idx].axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE26jFXe6Wkf"
      },
      "source": [
        "## Part 2. Loss function and optimization (<span style=\"color:green\">10 points</span>)\n",
        "#### The fun part start from here.\n",
        "*Definition:* loss function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. Loss function (sometime called cost function) is used to calculate the gradient by applying the chain rule, so that we can update the weights (and bias) of our neural network using optimizer such as gradient descent. <br>\n",
        "It could be interpreted as using loss function to calculate the network’s layers error, in which we calculate the error of the current layer, then pass the weighted error back to the previous layer, and recursively doing this until we travel back to the first hidden layer. At each layer, we update the weights using the derivative of the cost for each weight.\n",
        "\n",
        "Let illustrate this concept using a simple toy example.\n",
        "\n",
        "![toy.png](toy.png)\n",
        "<center> <strong> <font size=\"3\" color=\"blue\"> Figure 1. Toy example of backpropagation </font> </strong> </center>\n",
        "\n",
        "In **Fig. 1** we have a loss function $L$:\n",
        "\\begin{align}\n",
        "L = c \\times d\n",
        "\\end{align}\n",
        "\n",
        "where <br>\n",
        "\n",
        "\\begin{align}\n",
        "c = a + b -5\n",
        "\\end{align}\n",
        "\n",
        "and, <br>\n",
        "\n",
        "\\begin{align}\n",
        "d = b^2 + b -1\n",
        "\\end{align}\n",
        "\n",
        "As illustrated in **Fig. 1**, the equations in the edge show the partial derivation of some functions with respect to their direct variables. For example, $\\frac{\\partial L}{\\partial c}$ is the partial derivative of $L$ with respect to $c$. <br>\n",
        "However, we are actually interested in calculate the derivative of $L$ with respect to $a$ and $b$, which don't directly connected with each other. So, how can we do this? As mentioned earlier, we can do this using the chain-rule so that we can calculate $\\frac{\\partial L}{\\partial a}$ and $\\frac{\\partial L}{\\partial b}$ as:\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial a} = \\frac{\\partial L}{\\partial c} \\cdot \\frac{\\partial c}{\\partial a}\n",
        "\\end{align}\n",
        "\n",
        "and, <br>\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial c} \\cdot \\frac{\\partial c}{\\partial b} + \\frac{\\partial L}{\\partial d} \\cdot \\frac{\\partial d}{\\partial b}\n",
        "\\end{align}\n",
        "\n",
        "More importantly, **we can see that $a$ affect $L$ through $c$, and so on**. This concept hold no matter how many hidden layers you have or how complicated your loss will be as long as you use backpropagation to calculate the derivative to update your weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et5hx3Yu6Wkf"
      },
      "source": [
        "Now, let's get your hand dirty. Let's take a look at the model in **Fig. 2** below. This is the model we are gonna use in this assignment.\n",
        "\n",
        "![](NN.png)\n",
        "<center> <strong> <font size=\"4\" color=\"blue\"> Figure 2. Structure of our neural network </font> </strong> </center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBLnsw5Z6Wkg"
      },
      "source": [
        "### Construct model base on **Fig. 2** above (<span style=\"color:green\">4 points</span>)\n",
        "As shown in the **Fig. 2**, our neural network contains two hidden layer (we use 7 and 3 neurons as the  first hidden layer and the second hidden layer default setting respectively) and an output layer. To further simply things, we will not include biases in our model. Be aware that, while the number of neuron in the hidden layer can be abitrary, there must be 10 neurons in the output layer because we want our model to classify images from 10 classes. Based on the **Fig. 2**, you have to construct your network. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fDNSAMnD6Wkg"
      },
      "outputs": [],
      "source": [
        "# Numbers of input units\n",
        "num_input = X_train.shape[0]\n",
        "# Number of neural in your hidden layer\n",
        "# TODO: modify the number of neurons in the hidden layer\n",
        "num_hidden_1 = 21\n",
        "num_hidden_2 = 9\n",
        "\n",
        "# Construct your neural network from Fig. 2 (1.0 point)\n",
        "# TODO: Random initialize the hidden_1 layer weights (w/o bias)\n",
        "# Hints: use np.random.randn()\n",
        "W1 = np.random.randn(num_hidden_1, num_input)\n",
        "# TODO: Random initialize the hidden_2 layer weights (w/o bias)\n",
        "# Hints: use np.random.randn()\n",
        "W2 = np.random.randn(num_hidden_2, num_hidden_1)\n",
        "\n",
        "# TODO: Random initialize the output layer weights (w/o bias)\n",
        "# Hints: use np.random.randn()\n",
        "W3 = np.random.randn(10, num_hidden_2)\n",
        "\n",
        "def sigmoid(X):\n",
        "    # TODO: implement Eq. 2 (1.0 point)\n",
        "    # Hints: use np.exp()\n",
        "    return 1/(1+np.exp(-1*X))\n",
        "\n",
        "def softmax(X):\n",
        "    # TODO: implement Eq. 4 (1.0 point)\n",
        "    # Hints: use np.exp() and np.sum(, axis=0) <- beware of the axis\n",
        "    return np.exp(X)/np.sum(np.exp(X), axis=0)\n",
        "\n",
        "def cross_entropy_loss(Y, Y_pred):\n",
        "    # TODO: implement Eq. 5 (1.0 point)\n",
        "    # Hints: use np.sum(), np.multiply() and np.log()\n",
        "    # At the end, we need to divide by the number of of sample in the training batch e.g. M = Y.shape[1]\n",
        "    return (-1/Y.shape[1])*(np.sum(np.multiply(Y, np.log(Y_pred))))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEtfXEC16Wkg"
      },
      "source": [
        "According to the model in **Fig. 2**, our **forward-propagation** is going to start with the calculation of the output volume $A_1$ for the first hidden layer:\n",
        "\n",
        "\\begin{align}\n",
        "A_1 = \\sigma(Z_1) = \\sigma(W_1 X ) \\tag{1}\n",
        "\\end{align}\n",
        "where $W_1$ is the weights of the first hidden layer, $X$ is the input, and $\\sigma$ is the sigmoid activation where: <br>\n",
        "\\begin{align}\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}} \\tag{2}\n",
        "\\end{align}\n",
        "\n",
        "Then, we calculate the hidden volume of the second hidden layer $A_2$ by: <br>\n",
        "\\begin{align}\n",
        "A_2 = \\sigma(Z_2) = \\sigma(W_2 A_1 ) \\tag{3}\n",
        "\\end{align}\n",
        "where $W_2$ is the weights of the second hidden layer.\n",
        "\n",
        "Finally, we calculate the output volume of the output layer $A_3$ by: <br>\n",
        "\\begin{align}\n",
        "A_3 = S(Z_3) = S(W_3 A_2) \\tag{4}\n",
        "\\end{align}\n",
        "\n",
        "In **Eq. 4**, $W_3$ is the weights of the output layer, $A_2$ is the output volume of the last hidden layer, $S$ stands for softmax and defines by: <br>\n",
        "\\begin{align}\n",
        "S(x_i) = \\frac{e^{x_i}}{\\sum_{j=0}^{k} e^{x_j} } \\tag{5}\n",
        "\\end{align}\n",
        "where $i=0,1,..,k$. We use $k$ to represent classes, and $k=9$ in our case.\n",
        "\n",
        "Finally, we compute the loss function using:\n",
        "\n",
        "\\begin{align}\n",
        "L(Y, A_3) = - \\frac{1}{M} \\sum_{k=0}^{M} \\sum_{i=0}^{N} Y_i^{k} log({A_3}_i^{k}) \\tag{6}\n",
        "\\end{align}\n",
        "\n",
        "where $Y$ is the ground truth labels, $N$ is the number of classes, $M$ is the number of samples in the training batch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch4YH0Ma6Wkh"
      },
      "source": [
        "### Derivative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz423ZtX6Wkh"
      },
      "source": [
        "Using what you learnt in undergraduate school, let's calculate the **backward-propagation** for our model in **Fig. 2**. <br>\n",
        "As mentioned earlier, we are interested in $\\frac{\\partial L}{\\partial W_1}$, $\\frac{\\partial L}{\\partial W_2}$ and $\\frac{\\partial L}{\\partial W_3}$, where: \n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial W_3} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial W_3} \\tag{7}\n",
        "\\end{align}\n",
        "\n",
        ",<br>\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial W_2} \\tag{8}\n",
        "\\end{align}\n",
        "\n",
        "and, <br> \n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial W_1} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} \\cdot \\frac{\\partial Z_2} {\\partial A_1} \\cdot \\frac{\\partial A_1}{\\partial Z_1} \\cdot \\frac{\\partial Z_1}{\\partial W_1} \\tag{9}\n",
        "\\end{align}\n",
        " \n",
        "From **Eq. 6** we have: <br>\n",
        "\n",
        "The derivative of $L$ with respect to $Z_3$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial Z_3} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} = A_3 - Y \\tag{10}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $Z_3$ with respect to $W_3$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial Z_3}{\\partial W_3} = A_2 \\tag{11}\n",
        "\\end{align}\n",
        "\n",
        "From **Eq. 7** we have: <br>\n",
        "\n",
        "The derivative of $L$ with respect to $A_2$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial A_2} = (A_3 - Y) W_3\\tag{12}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $A_2$ with respect to $Z_2$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial A_2}{\\partial Z_2} = (A_2) (1 - A_2) \\tag{13}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $Z_2$ with respect to $W_2$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial Z_2}{\\partial W_2} = A_1 \\tag{14}\n",
        "\\end{align}\n",
        "\n",
        "From **Eq. 8** we have: <br>\n",
        "\n",
        "The derivative of $L$ with respect to $A_1$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial A_1} = (A_3 - Y) W_3 (A_2) (1 - A_2) W_2 \\tag{15}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $A_1$ with respect to $Z_1$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial A_1}{\\partial Z_1} = (A_1) (1 - A_1) \\tag{16}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $Z_1$ with respect to $W_1$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial Z_1}{\\partial W_1} = X \\tag{17}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnNak3Ux6Wkh"
      },
      "source": [
        "## Part. 3 Gradient check using finite-difference approximation. (<span style=\"color:green\">0.5 points</span>)\n",
        "\n",
        "When training deep neural network, there are many things that can go wrong. Until this point, you probably notice that we have been going on and on about the gradient. Why? Because the gradient is very important. Hence, you must making sure that the calculation of your gradient is correct. A correct gradient calculation won't promise your model will converge, but if the calculation was wrong your model will perform very weird. This type of error is hard to debug, so we better prevent it beforehand. <br> \n",
        "To perform the gradient check, we can calculate gradient using the [finite-difference approximation](https://en.wikipedia.org/wiki/Finite_difference) (FDA), and let's call the output of FDA numerical gradients. Then we compare this numerical gradients with the gradient we calculate from taking the derivative. If the differences between them are small enough, we can assume that the gradient was calculated correctly. <br>\n",
        "\n",
        "You probably learnt about FDA in your undergraduate, but to refresh your mind, let's have a simple example to see how FDA works. Assume that we have a function $f(x)$ which <br>\n",
        "\n",
        "\\begin{align}\n",
        "f(x) = \\frac{1}{3} x^3 - \\frac{1}{2} x^2 + 1 \\tag{18}\n",
        "\\end{align}\n",
        "\n",
        "Then, the derivative $\\Delta f$ will be: <br>\n",
        "\\begin{align}\n",
        "\\Delta f = x^2 - x \\tag{19}\n",
        "\\end{align}\n",
        "\n",
        "At $x=2.125$, using **Eq. 19** we have $\\Delta f = 2.390625$\n",
        "\n",
        "If we calculate the numerical gradient using FDA we have:\n",
        "\\begin{align}\n",
        "\\Delta_{num\\_grad} f = \\frac{f(x + \\epsilon) - f(x - \\epsilon)}{2 * \\epsilon}  \\tag{20}\n",
        "\\end{align}\n",
        "\n",
        "where $\\epsilon$ is a very small value (E.g. $\\epsilon = 1e-{04}$)\n",
        "\n",
        "At the same point $x=2.125$, using **Eq. 15** we have $\\Delta_{num\\_grad} f = 2.3906250033389753$ <br>\n",
        "\n",
        "We can see that, the calculated values of $\\Delta f$ and $\\Delta_{num\\_grad} f$ are very close to each other. <br>\n",
        "\n",
        "With the same idea, we can check the gradient calculation of our network using FDA. A simple way to do this is: <br>\n",
        "1) We wiggle (by a very small $\\epsilon$ values) the value of our weight for all of the parameters in our model. By all parameters, I mean all of the weights of $W_1$, $W_2$ and $W_3$. E.g. if we use 7 neurons in the first hidden layer and 3 neurons in the second hidden layer, the number of parameters in our network is : <br> \n",
        "$num\\_params(net) = num\\_params(W_1) + num\\_params(W_2) + num\\_params(W_3) = 28*28*7 + 7*7*3 + 3*10 = 5665$ <br>\n",
        "so we have to repeat the \"wiggling\" and calculate the numerical gradient 5665 times. At the end, we have a $num\\_grad$ vector that have shape (5665,) <br>\n",
        "2) Calculate the gradient by taking the derivative. Similarly, we will have a $grad$ vector that also have shape (5665,) <br>\n",
        "3) Compare $num\\_grad$ and $grad$ vectors by: <br>\n",
        "\\begin{align}\n",
        "grad\\_diff = \\frac{||grad - num\\_grad||_2}{|grad + num\\_grad|_2}  \\tag{21}\n",
        "\\end{align}\n",
        "\n",
        "If **grad_diff** is smaller than $1e-{08}$ than we assume that our gradient calculation is correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQs1Ezp26Wki"
      },
      "source": [
        "### Question: Why don't we use FDA to calculate the gradient to update our model? (<span style=\"color:green\">0.5 points</span>) <br>\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG372lFb6Wki"
      },
      "source": [
        "**Answer:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB1pOuSh6Wki"
      },
      "source": [
        "Using FDA comes with excessive calculation and it is not as efficient as the previous model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR7PkEj06Wki"
      },
      "source": [
        "### Hyper-parameters in your training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8kQPTYP6Wki",
        "outputId": "6ac4a17d-1fd3-4ae0-e95b-09d443e0bd78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num_trains: 60000, num_batchs: 468\n"
          ]
        }
      ],
      "source": [
        "# Flag use to enable/disable weight decay regularization\n",
        "is_weight_decay = True\n",
        "\n",
        "if is_weight_decay:\n",
        "    # Setting lambda coefficient for weight decay\n",
        "    lmda = np.exp(-7)\n",
        "\n",
        "# Seting learning rate and momentum for SGD\n",
        "learning_rate = 0.25\n",
        "beta = 0.5\n",
        "\n",
        "# Seting the number of training epochs\n",
        "epoch = 50\n",
        "# Choose your batch size\n",
        "batch_size = 128\n",
        "# Calculate the number of training iterations base on the number of training samples and your batch size\n",
        "num_batchs = num_trains // batch_size\n",
        "\n",
        "print(\"Num_trains: {}, num_batchs: {}\".format(num_trains, num_batchs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsLqADBo6Wkj"
      },
      "source": [
        "### Training your network (<span style=\"color:green\">9.5 points</span>)\n",
        "\n",
        "In this assignment, we will train our model using mini-batch stochatic gradient descent with momentum. To know more about this optimization algorithm, please check out this great [video](https://www.youtube.com/watch?v=k8fTYJPd3_I) from Dr. Andrew Ng. <br>\n",
        "For this assignment, we will use the implementation from **Eq. 22** and **Eq. 23** <br>\n",
        "\n",
        "\\begin{align}\n",
        "v_{dW} = \\beta v_{dW} + (1 - \\beta) dW \\tag{22}\n",
        "\\end{align}\n",
        "\\begin{align}\n",
        "W = W - \\alpha v_{dW} \\tag{23}\n",
        "\\end{align}\n",
        "\n",
        "If you are curious, you can modify the hyper-params in the above section at your will."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EjVj6QBE6Wkj",
        "outputId": "269bc47d-d211-41bb-dbc1-c6c9cb12c4dc",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div id='b1643272-6bc3-43e1-afb5-06183eb48512'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch/Iterations]:[0/0], loss: 12.334371403928717\n",
            "[Epoch/Iterations]:[0/100], loss: 9.31171171010917\n",
            "[Epoch/Iterations]:[0/200], loss: 9.06534707376491\n",
            "[Epoch/Iterations]:[0/300], loss: 8.927320991286539\n",
            "[Epoch/Iterations]:[0/400], loss: 8.852407209522905\n",
            "=> Elapsed time epoch #0 : 0.94 seconds\n",
            "[Epoch/Iterations]:[1/0], loss: 8.646670673354638\n",
            "[Epoch/Iterations]:[1/100], loss: 8.635900066218447\n",
            "[Epoch/Iterations]:[1/200], loss: 8.687254450539251\n",
            "[Epoch/Iterations]:[1/300], loss: 8.586472768750111\n",
            "[Epoch/Iterations]:[1/400], loss: 8.666814778091767\n",
            "=> Elapsed time epoch #1 : 1.00 seconds\n",
            "[Epoch/Iterations]:[2/0], loss: 8.573046498608928\n",
            "[Epoch/Iterations]:[2/100], loss: 8.425978017311422\n",
            "[Epoch/Iterations]:[2/200], loss: 8.612418283763937\n",
            "[Epoch/Iterations]:[2/300], loss: 8.470609963317454\n",
            "[Epoch/Iterations]:[2/400], loss: 8.44239004249198\n",
            "=> Elapsed time epoch #2 : 0.77 seconds\n",
            "[Epoch/Iterations]:[3/0], loss: 8.57421281444201\n",
            "[Epoch/Iterations]:[3/100], loss: 8.557844608968205\n",
            "[Epoch/Iterations]:[3/200], loss: 8.507446962963924\n",
            "[Epoch/Iterations]:[3/300], loss: 8.528181863466788\n",
            "[Epoch/Iterations]:[3/400], loss: 8.49124862720972\n",
            "=> Elapsed time epoch #3 : 0.73 seconds\n",
            "[Epoch/Iterations]:[4/0], loss: 8.358132374435533\n",
            "[Epoch/Iterations]:[4/100], loss: 8.230682612051682\n",
            "[Epoch/Iterations]:[4/200], loss: 8.46676006319546\n",
            "[Epoch/Iterations]:[4/300], loss: 8.376483476299185\n",
            "[Epoch/Iterations]:[4/400], loss: 8.232194771588356\n",
            "=> Elapsed time epoch #4 : 0.78 seconds\n",
            "[Epoch/Iterations]:[5/0], loss: 8.382814143705094\n",
            "[Epoch/Iterations]:[5/100], loss: 8.507975771606695\n",
            "[Epoch/Iterations]:[5/200], loss: 8.417322052343673\n",
            "[Epoch/Iterations]:[5/300], loss: 8.380619546313973\n",
            "[Epoch/Iterations]:[5/400], loss: 8.35744196475114\n",
            "=> Elapsed time epoch #5 : 1.05 seconds\n",
            "[Epoch/Iterations]:[6/0], loss: 8.335798242555313\n",
            "[Epoch/Iterations]:[6/100], loss: 8.30660408942479\n",
            "[Epoch/Iterations]:[6/200], loss: 8.421585233067727\n",
            "[Epoch/Iterations]:[6/300], loss: 8.369332885826005\n",
            "[Epoch/Iterations]:[6/400], loss: 8.333656854008277\n",
            "=> Elapsed time epoch #6 : 0.97 seconds\n",
            "[Epoch/Iterations]:[7/0], loss: 8.397569990021656\n",
            "[Epoch/Iterations]:[7/100], loss: 8.347087408229456\n",
            "[Epoch/Iterations]:[7/200], loss: 8.402694488265698\n",
            "[Epoch/Iterations]:[7/300], loss: 8.293311070273031\n",
            "[Epoch/Iterations]:[7/400], loss: 8.220595596614219\n",
            "=> Elapsed time epoch #7 : 0.79 seconds\n",
            "[Epoch/Iterations]:[8/0], loss: 8.234893954204237\n",
            "[Epoch/Iterations]:[8/100], loss: 8.34953407113946\n",
            "[Epoch/Iterations]:[8/200], loss: 8.479017592803542\n",
            "[Epoch/Iterations]:[8/300], loss: 8.495771208350797\n",
            "[Epoch/Iterations]:[8/400], loss: 8.214534839040011\n",
            "=> Elapsed time epoch #8 : 0.75 seconds\n",
            "[Epoch/Iterations]:[9/0], loss: 8.25628393651024\n",
            "[Epoch/Iterations]:[9/100], loss: 8.347345164849049\n",
            "[Epoch/Iterations]:[9/200], loss: 8.388187862160912\n",
            "[Epoch/Iterations]:[9/300], loss: 8.197990340916228\n",
            "[Epoch/Iterations]:[9/400], loss: 8.25731340540993\n",
            "=> Elapsed time epoch #9 : 0.75 seconds\n",
            "[Epoch/Iterations]:[10/0], loss: 8.413437729331061\n",
            "[Epoch/Iterations]:[10/100], loss: 8.251011658938321\n",
            "[Epoch/Iterations]:[10/200], loss: 8.1698545354667\n",
            "[Epoch/Iterations]:[10/300], loss: 8.164358064760746\n",
            "[Epoch/Iterations]:[10/400], loss: 8.27651522312817\n",
            "=> Elapsed time epoch #10 : 0.77 seconds\n",
            "[Epoch/Iterations]:[11/0], loss: 8.333659365235716\n",
            "[Epoch/Iterations]:[11/100], loss: 8.283633721920832\n",
            "[Epoch/Iterations]:[11/200], loss: 8.151036853555446\n",
            "[Epoch/Iterations]:[11/300], loss: 8.251935270024397\n",
            "[Epoch/Iterations]:[11/400], loss: 8.34266991470086\n",
            "=> Elapsed time epoch #11 : 0.78 seconds\n",
            "[Epoch/Iterations]:[12/0], loss: 8.369709220073233\n",
            "[Epoch/Iterations]:[12/100], loss: 8.309859749257138\n",
            "[Epoch/Iterations]:[12/200], loss: 8.243461010139924\n",
            "[Epoch/Iterations]:[12/300], loss: 8.31099551689513\n",
            "[Epoch/Iterations]:[12/400], loss: 8.15792072249508\n",
            "=> Elapsed time epoch #12 : 0.77 seconds\n",
            "[Epoch/Iterations]:[13/0], loss: 8.322935561325282\n",
            "[Epoch/Iterations]:[13/100], loss: 8.35453034992157\n",
            "[Epoch/Iterations]:[13/200], loss: 8.247965302467348\n",
            "[Epoch/Iterations]:[13/300], loss: 8.056581668466013\n",
            "[Epoch/Iterations]:[13/400], loss: 8.389172894131962\n",
            "=> Elapsed time epoch #13 : 0.74 seconds\n",
            "[Epoch/Iterations]:[14/0], loss: 8.090300448495718\n",
            "[Epoch/Iterations]:[14/100], loss: 8.235325486912528\n",
            "[Epoch/Iterations]:[14/200], loss: 8.190707569295634\n",
            "[Epoch/Iterations]:[14/300], loss: 8.148631009484655\n",
            "[Epoch/Iterations]:[14/400], loss: 8.120360886480968\n",
            "=> Elapsed time epoch #14 : 0.72 seconds\n",
            "[Epoch/Iterations]:[15/0], loss: 8.089043470166196\n",
            "[Epoch/Iterations]:[15/100], loss: 8.108022374663905\n",
            "[Epoch/Iterations]:[15/200], loss: 8.301647354805864\n",
            "[Epoch/Iterations]:[15/300], loss: 8.173936982046635\n",
            "[Epoch/Iterations]:[15/400], loss: 8.230095782959356\n",
            "=> Elapsed time epoch #15 : 0.72 seconds\n",
            "[Epoch/Iterations]:[16/0], loss: 8.15536541109969\n",
            "[Epoch/Iterations]:[16/100], loss: 8.158387082500951\n",
            "[Epoch/Iterations]:[16/200], loss: 8.097113984844276\n",
            "[Epoch/Iterations]:[16/300], loss: 8.145651135206382\n",
            "[Epoch/Iterations]:[16/400], loss: 8.10882717652257\n",
            "=> Elapsed time epoch #16 : 0.73 seconds\n",
            "[Epoch/Iterations]:[17/0], loss: 8.055631098586755\n",
            "[Epoch/Iterations]:[17/100], loss: 8.070789800697543\n",
            "[Epoch/Iterations]:[17/200], loss: 8.030264544335886\n",
            "[Epoch/Iterations]:[17/300], loss: 7.946447957293679\n",
            "[Epoch/Iterations]:[17/400], loss: 8.059055036536876\n",
            "=> Elapsed time epoch #17 : 0.73 seconds\n",
            "[Epoch/Iterations]:[18/0], loss: 8.064535522027173\n",
            "[Epoch/Iterations]:[18/100], loss: 8.21201917358551\n",
            "[Epoch/Iterations]:[18/200], loss: 8.146262733368447\n",
            "[Epoch/Iterations]:[18/300], loss: 8.111340527802472\n",
            "[Epoch/Iterations]:[18/400], loss: 8.081408892660018\n",
            "=> Elapsed time epoch #18 : 0.84 seconds\n",
            "[Epoch/Iterations]:[19/0], loss: 8.09368364348063\n",
            "[Epoch/Iterations]:[19/100], loss: 8.185797669135972\n",
            "[Epoch/Iterations]:[19/200], loss: 8.108466319146531\n",
            "[Epoch/Iterations]:[19/300], loss: 7.990712807440628\n",
            "[Epoch/Iterations]:[19/400], loss: 8.155257600979166\n",
            "=> Elapsed time epoch #19 : 0.97 seconds\n",
            "[Epoch/Iterations]:[20/0], loss: 7.979402837825965\n",
            "[Epoch/Iterations]:[20/100], loss: 7.940950583393565\n",
            "[Epoch/Iterations]:[20/200], loss: 8.035797179095955\n",
            "[Epoch/Iterations]:[20/300], loss: 8.033340494496871\n",
            "[Epoch/Iterations]:[20/400], loss: 8.103924587375555\n",
            "=> Elapsed time epoch #20 : 0.88 seconds\n",
            "[Epoch/Iterations]:[21/0], loss: 8.03296142865073\n",
            "[Epoch/Iterations]:[21/100], loss: 7.9634850257561824\n",
            "[Epoch/Iterations]:[21/200], loss: 8.019997227442868\n",
            "[Epoch/Iterations]:[21/300], loss: 8.083540958010468\n",
            "[Epoch/Iterations]:[21/400], loss: 7.943181152116281\n",
            "=> Elapsed time epoch #21 : 0.81 seconds\n",
            "[Epoch/Iterations]:[22/0], loss: 8.027098737663524\n",
            "[Epoch/Iterations]:[22/100], loss: 8.152611442327775\n",
            "[Epoch/Iterations]:[22/200], loss: 8.001971626838891\n",
            "[Epoch/Iterations]:[22/300], loss: 8.056869607096157\n",
            "[Epoch/Iterations]:[22/400], loss: 8.067012549746789\n",
            "=> Elapsed time epoch #22 : 0.86 seconds\n",
            "[Epoch/Iterations]:[23/0], loss: 7.970552711279909\n",
            "[Epoch/Iterations]:[23/100], loss: 8.045431792966747\n",
            "[Epoch/Iterations]:[23/200], loss: 8.028803204368769\n",
            "[Epoch/Iterations]:[23/300], loss: 7.965495779400431\n",
            "[Epoch/Iterations]:[23/400], loss: 7.980517990490094\n",
            "=> Elapsed time epoch #23 : 0.74 seconds\n",
            "[Epoch/Iterations]:[24/0], loss: 8.107585690170582\n",
            "[Epoch/Iterations]:[24/100], loss: 8.13484584639857\n",
            "[Epoch/Iterations]:[24/200], loss: 7.981784128670438\n",
            "[Epoch/Iterations]:[24/300], loss: 8.001774747994963\n",
            "[Epoch/Iterations]:[24/400], loss: 8.029545026698925\n",
            "=> Elapsed time epoch #24 : 0.72 seconds\n",
            "[Epoch/Iterations]:[25/0], loss: 7.86082040305759\n",
            "[Epoch/Iterations]:[25/100], loss: 8.065656980939313\n",
            "[Epoch/Iterations]:[25/200], loss: 8.077069392928586\n",
            "[Epoch/Iterations]:[25/300], loss: 7.9131597286153506\n",
            "[Epoch/Iterations]:[25/400], loss: 7.949963825400808\n",
            "=> Elapsed time epoch #25 : 0.76 seconds\n",
            "[Epoch/Iterations]:[26/0], loss: 7.868511835475875\n",
            "[Epoch/Iterations]:[26/100], loss: 7.8899504747783675\n",
            "[Epoch/Iterations]:[26/200], loss: 8.00396010774648\n",
            "[Epoch/Iterations]:[26/300], loss: 8.016995122997608\n",
            "[Epoch/Iterations]:[26/400], loss: 7.988493633397922\n",
            "=> Elapsed time epoch #26 : 0.69 seconds\n",
            "[Epoch/Iterations]:[27/0], loss: 7.907648519374061\n",
            "[Epoch/Iterations]:[27/100], loss: 7.97024919177653\n",
            "[Epoch/Iterations]:[27/200], loss: 7.920351253803327\n",
            "[Epoch/Iterations]:[27/300], loss: 8.05618983540876\n",
            "[Epoch/Iterations]:[27/400], loss: 8.010000207057232\n",
            "=> Elapsed time epoch #27 : 0.76 seconds\n",
            "[Epoch/Iterations]:[28/0], loss: 8.011234014720381\n",
            "[Epoch/Iterations]:[28/100], loss: 7.966271841457732\n",
            "[Epoch/Iterations]:[28/200], loss: 8.007988125288271\n",
            "[Epoch/Iterations]:[28/300], loss: 8.047040473972105\n",
            "[Epoch/Iterations]:[28/400], loss: 7.804786538303702\n",
            "=> Elapsed time epoch #28 : 0.72 seconds\n",
            "[Epoch/Iterations]:[29/0], loss: 8.036481131743708\n",
            "[Epoch/Iterations]:[29/100], loss: 8.08501911267435\n",
            "[Epoch/Iterations]:[29/200], loss: 7.82860209983575\n",
            "[Epoch/Iterations]:[29/300], loss: 7.941142210077079\n",
            "[Epoch/Iterations]:[29/400], loss: 7.882739793394715\n",
            "=> Elapsed time epoch #29 : 0.73 seconds\n",
            "[Epoch/Iterations]:[30/0], loss: 7.963150559886681\n",
            "[Epoch/Iterations]:[30/100], loss: 7.953922269728161\n",
            "[Epoch/Iterations]:[30/200], loss: 7.894697969974216\n",
            "[Epoch/Iterations]:[30/300], loss: 8.021324619312416\n",
            "[Epoch/Iterations]:[30/400], loss: 7.964534423413011\n",
            "=> Elapsed time epoch #30 : 0.73 seconds\n",
            "[Epoch/Iterations]:[31/0], loss: 8.043252731286847\n",
            "[Epoch/Iterations]:[31/100], loss: 7.97072921552389\n",
            "[Epoch/Iterations]:[31/200], loss: 7.870184321162106\n",
            "[Epoch/Iterations]:[31/300], loss: 7.954013632151787\n",
            "[Epoch/Iterations]:[31/400], loss: 7.957657476864113\n",
            "=> Elapsed time epoch #31 : 0.72 seconds\n",
            "[Epoch/Iterations]:[32/0], loss: 7.923291321876904\n",
            "[Epoch/Iterations]:[32/100], loss: 7.972328693422516\n",
            "[Epoch/Iterations]:[32/200], loss: 7.835398189717785\n",
            "[Epoch/Iterations]:[32/300], loss: 7.772386411919825\n",
            "[Epoch/Iterations]:[32/400], loss: 7.858291233367078\n",
            "=> Elapsed time epoch #32 : 0.74 seconds\n",
            "[Epoch/Iterations]:[33/0], loss: 7.824618753584873\n",
            "[Epoch/Iterations]:[33/100], loss: 7.733399582687181\n",
            "[Epoch/Iterations]:[33/200], loss: 7.9651271919251965\n",
            "[Epoch/Iterations]:[33/300], loss: 7.854022673122836\n",
            "[Epoch/Iterations]:[33/400], loss: 7.944615735590594\n",
            "=> Elapsed time epoch #33 : 0.74 seconds\n",
            "[Epoch/Iterations]:[34/0], loss: 7.736177224417125\n",
            "[Epoch/Iterations]:[34/100], loss: 7.913860698720305\n",
            "[Epoch/Iterations]:[34/200], loss: 7.797179075872584\n",
            "[Epoch/Iterations]:[34/300], loss: 7.817373948411467\n",
            "[Epoch/Iterations]:[34/400], loss: 7.8740867854475\n",
            "=> Elapsed time epoch #34 : 0.73 seconds\n",
            "[Epoch/Iterations]:[35/0], loss: 7.927637724369999\n",
            "[Epoch/Iterations]:[35/100], loss: 7.892685987629992\n",
            "[Epoch/Iterations]:[35/200], loss: 7.850650342826963\n",
            "[Epoch/Iterations]:[35/300], loss: 7.872458244011041\n",
            "[Epoch/Iterations]:[35/400], loss: 7.964972180341024\n",
            "=> Elapsed time epoch #35 : 0.72 seconds\n",
            "[Epoch/Iterations]:[36/0], loss: 7.8620163407102215\n",
            "[Epoch/Iterations]:[36/100], loss: 7.807425815191732\n",
            "[Epoch/Iterations]:[36/200], loss: 7.7907103710584975\n",
            "[Epoch/Iterations]:[36/300], loss: 7.675199854768483\n",
            "[Epoch/Iterations]:[36/400], loss: 7.782382785681508\n",
            "=> Elapsed time epoch #36 : 0.79 seconds\n",
            "[Epoch/Iterations]:[37/0], loss: 7.887778984800063\n",
            "[Epoch/Iterations]:[37/100], loss: 7.969138480236372\n",
            "[Epoch/Iterations]:[37/200], loss: 7.822940615013356\n",
            "[Epoch/Iterations]:[37/300], loss: 7.84326068745858\n",
            "[Epoch/Iterations]:[37/400], loss: 7.709204546105458\n",
            "=> Elapsed time epoch #37 : 0.94 seconds\n",
            "[Epoch/Iterations]:[38/0], loss: 7.750669325436668\n",
            "[Epoch/Iterations]:[38/100], loss: 7.783383158989687\n",
            "[Epoch/Iterations]:[38/200], loss: 7.955031834551345\n",
            "[Epoch/Iterations]:[38/300], loss: 7.770280286985939\n",
            "[Epoch/Iterations]:[38/400], loss: 7.7953284592447405\n",
            "=> Elapsed time epoch #38 : 0.99 seconds\n",
            "[Epoch/Iterations]:[39/0], loss: 7.684170273533158\n",
            "[Epoch/Iterations]:[39/100], loss: 7.752691642679994\n",
            "[Epoch/Iterations]:[39/200], loss: 7.813659281316137\n",
            "[Epoch/Iterations]:[39/300], loss: 7.74389641879015\n",
            "[Epoch/Iterations]:[39/400], loss: 7.828261254488071\n",
            "=> Elapsed time epoch #39 : 0.80 seconds\n",
            "[Epoch/Iterations]:[40/0], loss: 7.639459491366676\n",
            "[Epoch/Iterations]:[40/100], loss: 7.859970405949796\n",
            "[Epoch/Iterations]:[40/200], loss: 7.895497871477657\n",
            "[Epoch/Iterations]:[40/300], loss: 7.626453759419212\n",
            "[Epoch/Iterations]:[40/400], loss: 7.840476640444024\n",
            "=> Elapsed time epoch #40 : 0.90 seconds\n",
            "[Epoch/Iterations]:[41/0], loss: 7.731848351426578\n",
            "[Epoch/Iterations]:[41/100], loss: 7.863606119774729\n",
            "[Epoch/Iterations]:[41/200], loss: 7.816350394962147\n",
            "[Epoch/Iterations]:[41/300], loss: 7.754937888222266\n",
            "[Epoch/Iterations]:[41/400], loss: 7.7061948678796\n",
            "=> Elapsed time epoch #41 : 0.78 seconds\n",
            "[Epoch/Iterations]:[42/0], loss: 7.724029493584641\n",
            "[Epoch/Iterations]:[42/100], loss: 7.781737755289434\n",
            "[Epoch/Iterations]:[42/200], loss: 7.758177841418276\n",
            "[Epoch/Iterations]:[42/300], loss: 7.676422454910401\n",
            "[Epoch/Iterations]:[42/400], loss: 7.894514779936295\n",
            "=> Elapsed time epoch #42 : 0.81 seconds\n",
            "[Epoch/Iterations]:[43/0], loss: 7.621360828236186\n",
            "[Epoch/Iterations]:[43/100], loss: 7.814994347023684\n",
            "[Epoch/Iterations]:[43/200], loss: 7.711397088323572\n",
            "[Epoch/Iterations]:[43/300], loss: 7.665227515329812\n",
            "[Epoch/Iterations]:[43/400], loss: 7.744587777959228\n",
            "=> Elapsed time epoch #43 : 0.77 seconds\n",
            "[Epoch/Iterations]:[44/0], loss: 7.696200125769706\n",
            "[Epoch/Iterations]:[44/100], loss: 7.743297591517106\n",
            "[Epoch/Iterations]:[44/200], loss: 7.66874438644978\n",
            "[Epoch/Iterations]:[44/300], loss: 7.6614759989310475\n",
            "[Epoch/Iterations]:[44/400], loss: 7.934986659185334\n",
            "=> Elapsed time epoch #44 : 0.72 seconds\n",
            "[Epoch/Iterations]:[45/0], loss: 7.751629116706232\n",
            "[Epoch/Iterations]:[45/100], loss: 7.69933794708552\n",
            "[Epoch/Iterations]:[45/200], loss: 7.8543278342999185\n",
            "[Epoch/Iterations]:[45/300], loss: 7.671819519445866\n",
            "[Epoch/Iterations]:[45/400], loss: 7.647751285983968\n",
            "=> Elapsed time epoch #45 : 0.74 seconds\n",
            "[Epoch/Iterations]:[46/0], loss: 7.767388397491969\n",
            "[Epoch/Iterations]:[46/100], loss: 7.691415728951025\n",
            "[Epoch/Iterations]:[46/200], loss: 7.75097130467667\n",
            "[Epoch/Iterations]:[46/300], loss: 7.6374863759521165\n",
            "[Epoch/Iterations]:[46/400], loss: 7.704533441453629\n",
            "=> Elapsed time epoch #46 : 0.73 seconds\n",
            "[Epoch/Iterations]:[47/0], loss: 7.636931404315407\n",
            "[Epoch/Iterations]:[47/100], loss: 7.703608048144349\n",
            "[Epoch/Iterations]:[47/200], loss: 7.714785744554902\n",
            "[Epoch/Iterations]:[47/300], loss: 7.701358616182321\n",
            "[Epoch/Iterations]:[47/400], loss: 7.62811566981499\n",
            "=> Elapsed time epoch #47 : 0.82 seconds\n",
            "[Epoch/Iterations]:[48/0], loss: 7.595689194179579\n",
            "[Epoch/Iterations]:[48/100], loss: 7.57744010685728\n",
            "[Epoch/Iterations]:[48/200], loss: 7.703113683145217\n",
            "[Epoch/Iterations]:[48/300], loss: 7.700299058407604\n",
            "[Epoch/Iterations]:[48/400], loss: 7.6784905259106235\n",
            "=> Elapsed time epoch #48 : 0.78 seconds\n",
            "[Epoch/Iterations]:[49/0], loss: 7.70238272200196\n",
            "[Epoch/Iterations]:[49/100], loss: 7.634813284082225\n",
            "[Epoch/Iterations]:[49/200], loss: 7.762814991754323\n",
            "[Epoch/Iterations]:[49/300], loss: 7.633886329055275\n",
            "[Epoch/Iterations]:[49/400], loss: 7.6180581219252925\n",
            "=> Elapsed time epoch #49 : 0.73 seconds\n"
          ]
        }
      ],
      "source": [
        "# Define an interactive ipython figure to display the training loss\n",
        "%matplotlib notebook\n",
        "fig = plt.figure(\"Training loss\")\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "plt.ion()\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "# Log the training loss\n",
        "loss_log = []\n",
        "\n",
        "# Zeros initialize the momentum for SGD\n",
        "V_dW1 = np.zeros(W1.shape)\n",
        "V_dW2 = np.zeros(W2.shape)\n",
        "V_dW3 = np.zeros(W3.shape)\n",
        "\n",
        "# Training\n",
        "for i in range(epoch):\n",
        "    start_t = time.time()\n",
        "    \n",
        "    # Random shuffle training data every training epoch\n",
        "    np.random.seed(np.random.randint(num_trains))\n",
        "    indices = np.random.permutation(num_trains)\n",
        "    X_train_shuffled, Y_train_shuffled = X_train[:, indices], Y_train[:, indices]\n",
        "\n",
        "    for j in range(num_batchs):\n",
        "\n",
        "        # Get mini-batch samples for training\n",
        "        start_idx = j * batch_size\n",
        "        end_idx = min(j * batch_size + batch_size, X_train.shape[1] - 1)\n",
        "        X, Y = X_train_shuffled[:, start_idx : end_idx], Y_train_shuffled[:, start_idx : end_idx]\n",
        "        # Size of actual mini-batch, it could be smaller than batch_size\n",
        "        mini_batch = end_idx - start_idx\n",
        "        \n",
        "        # TODO: implement the forward-pass (1.0 point)\n",
        "        Z1 = np.matmul(W1, X)\n",
        "        A1 = sigmoid(Z1)\n",
        "        Z2 = np.matmul(W2, A1)\n",
        "        A2 = sigmoid(Z2)\n",
        "        Z3 = np.matmul(W3, A2)\n",
        "        A3 = softmax(Z3)\n",
        "        \n",
        "\n",
        "        if is_weight_decay: \n",
        "            # TODO: call cross entropy loss with weight decay regularization\n",
        "            # We need to penalize both W1, W2 and W3 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            L = cross_entropy_loss(Y, A3) + lmda * 0.5 * (np.sum(W1*W1) + np.sum(W2*W2) + np.sum(W3*W3))\n",
        "            \n",
        "        else:\n",
        "            # TODO: call cross entropy loss (0.5 point)\n",
        "            L = cross_entropy_loss(Y, A3)\n",
        "            \n",
        "        \n",
        "        # Log the training loss during training\n",
        "        loss_log.append(L)\n",
        "        \n",
        "\n",
        "        # TODO: calculate the derivative of 𝐿 with respect to 𝑍3 using eq. 10 (1.0 point)\n",
        "        dZ3 = A3 - Y\n",
        "        \n",
        "        if is_weight_decay:\n",
        "            # TODO: calculate the derivative of 𝐿 with respect to W3 using eq. 7 with weight decay regularization\n",
        "            # We only need penalize and W3 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            dW3 = (1/batch_size) * (np.matmul(dZ3, np.transpose(A2)) + lmda * W3)\n",
        "            \n",
        "        else:\n",
        "            # TODO: calculate the derivative of 𝐿 with respect to W2 using eq. 7 (0.5 point)\n",
        "            # Hints: consider the mini_batch during the calculation of the gradient\n",
        "            # use np.matmul() and transpose the matrix to fit the dimension\n",
        "            dW3 = (1/batch_size) * np.matmul(dZ3, np.transpose(A2))\n",
        "        \n",
        "        \n",
        "        # TODO: calculate the derivative of 𝐿 with respect to A2 using eq. 12 (1.0 point)\n",
        "        # Hints: use np.matmul() and transpose the matrix to fit the dimension\n",
        "        dA2 = np.matmul(np.transpose(W3), dZ3)\n",
        "        \n",
        "        # TODO: calculate the derivative of 𝐿 with respect to Z2 using eq. 12 and eq. 13 (1.0 point)\n",
        "        # Hints: use element-wise multiplication * \n",
        "        dZ2 = dA2 * (A2 * (1 - A2))\n",
        "        \n",
        "        if is_weight_decay:\n",
        "            # TODO: calculate the derivative of 𝐿 with respect to W2 using eq. 7 with weight decay regularization\n",
        "            # We only need penalize and W1 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            dW2 =(1/batch_size) * (np.matmul(dZ2, np.transpose(A1)) + lmda * W2)\n",
        "            \n",
        "        else:\n",
        "            # TODO: calculate the derivative of 𝐿 with respect to W2 using eq. 8 (0.5 point)\n",
        "            # Hints: similarly, consider the mini_batch during the calculation of the gradient\n",
        "            # use np.matmul() and transpose the matrix to fit the dimension\n",
        "            dW2 = (1/batch_size) * np.matmul(dZ2, np.transpose(A1)) \n",
        "            \n",
        "        # TODO: calculate the derivative of 𝐿 with respect to A1 using eq. 15 (1.0 point)\n",
        "        # Hints: use np.matmul() and transpose the matrix to fit the dimension\n",
        "        dA1 = np.matmul(np.transpose(W2), dZ2)\n",
        "        \n",
        "        # TODO: calculate the derivative of 𝐿 with respect to Z1 using eq. 15 and eq. 16 (1.0 point)\n",
        "        # Hints: use element-wise multiplication * \n",
        "        dZ1 = dA1 * (A1 * (1 - A1))\n",
        "        \n",
        "        if is_weight_decay:\n",
        "            # TODO: calculate the derivative of 𝐿 with respect to W1 using eq. 9 with weight decay regularization\n",
        "            # We only need penalize and W1 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            dW1 = (1/batch_size) * (np.matmul(dZ1, np.transpose(X)) + lmda * W1)\n",
        "            \n",
        "        else:\n",
        "            # TODO: calculate the derivative of 𝐿 with respect to W1 using eq. 9 (0.5 point)\n",
        "            # Hints: similarly, consider the mini_batch during the calculation of the gradient\n",
        "            # use np.matmul() and transpose the matrix to fit the dimension\n",
        "            dW1 = (1/batch_size) * (np.matmul(dZ1, np.transpose(X)))\n",
        "        \n",
        "        # TODO: Update the learning velocity using Eq. 22 (1.0 point)\n",
        "        V_dW1 = beta * V_dW1 + (1 - beta) * dW1\n",
        "        V_dW2 = beta * V_dW2 + (1 - beta) * dW2\n",
        "        V_dW3 = beta * V_dW3 + (1 - beta) * dW3\n",
        "\n",
        "        # TODO: Update the model weights using Eq. 23 (1.0 point)\n",
        "        W1 = W1 - (learning_rate * V_dW1)\n",
        "        W2 = W2 - (learning_rate * V_dW2)\n",
        "        W3 = W3 - (learning_rate * V_dW3)\n",
        "\n",
        "        if (j % 100 == 0):\n",
        "            print(\"[Epoch/Iterations]:[{}/{}], loss: {}\".format(i, j, L))\n",
        "            \n",
        "    ax.clear()\n",
        "    ax.plot(loss_log)\n",
        "    fig.canvas.draw()\n",
        "    print(\"=> Elapsed time epoch #{} : {:.2f} seconds\".format(i, time.time() - start_t))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZGoEO66Wkk"
      },
      "source": [
        "### Evaluate the performance of your model (<span style=\"color:green\">0.5 points</span>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQwvDA9J6Wkk",
        "outputId": "95c697fb-1ff4-4086-dbf0-37dbe1b9ad78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[759   3  17  65   7   2 131   0  16   0]\n",
            " [  5 948   6  27   9   0   5   0   0   0]\n",
            " [ 10   1 696  11 192   1  80   0   9   0]\n",
            " [ 31  15  11 840  59   1  38   0   5   0]\n",
            " [  1   1  94  30 810   0  60   0   4   0]\n",
            " [  0   0   1   1   0 920   1  35  10  32]\n",
            " [127   3 124  48 136   0 539   0  23   0]\n",
            " [  0   0   0   0   0  41   0 885   0  74]\n",
            " [  4   0  15   6   6  10  34   7 917   1]\n",
            " [  0   0   0   0   0  25   0  31   2 942]]\n",
            "Testing accuracy: 0.8256\n"
          ]
        }
      ],
      "source": [
        "# TODO: implement the forward-pass (0.5 point)\n",
        "# Hints: note that this is similar but not exactly the same as the forward pass during training\n",
        "Z1 = np.matmul(W1, X_test)\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.matmul(W2, A1)\n",
        "A2 = sigmoid(Z2)\n",
        "Z3 = np.matmul(W3, A2)\n",
        "A3 = softmax(Z3)\n",
        "\n",
        "# Evaluate the performance of your NN\n",
        "predictions = np.argmax(A3, axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(labels, predictions)))\n",
        "print(\"Testing accuracy: {}\".format(accuracy_score(labels, predictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPrvXDZ-6Wkl"
      },
      "source": [
        "## Part 4. Regularization and NN simple tunning (<span style=\"color:green\">2.5 points</span>)\n",
        "\n",
        "1. Applying weight decay (<span style=\"color:green\">1.5 point</span> )\n",
        "  * Using what you learnt from assignment 1 to add the code at neccesary parts in **Training your network** above.\n",
        "  * There are 3 spots, (<span style=\"color:green\">0.5 point</span>) each spot. Insert the answers in above section.\n",
        "2. Change the number of neurons in the hidden layer and report the performance (<span style=\"color:green\">1 point</span>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncXMyawa6Wkl"
      },
      "source": [
        "**Answer of question 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsfwDHz56Wkl"
      },
      "source": [
        "Current Testing Accuracy = 0.7221. Now we change the networks with these following network nodes:\n",
        "* Layer 1: 21 , Layer 2: 9 (multiple 3) - Testing accuracy: 0.8271.\n",
        "\n",
        "I can conclude that with extending the number of neurons in each layer we could reach a better accuracy. However, it is not necessarily mean that \"The more nodes, the better\"."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
